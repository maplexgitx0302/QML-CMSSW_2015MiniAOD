{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMS Jet Data Machine Learning with Arc Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jet\n",
    "import uproot\n",
    "import awkward as ak\n",
    "\n",
    "import pennylane as qml\n",
    "import pennylane.numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "GPU = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classical layers and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicalModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, hidden_layers):\n",
    "        super().__init__()\n",
    "        if hidden_layers == 0:\n",
    "            net = [nn.Linear(input_dim, 1)]\n",
    "        else:\n",
    "            net = [nn.Linear(input_dim, hidden_dim), nn.ReLU()]\n",
    "            for _ in range(hidden_layers-1):\n",
    "                net += [nn.Linear(hidden_dim, hidden_dim)]\n",
    "                net += [nn.ReLU()]\n",
    "            net += [nn.Linear(hidden_dim, 1)]\n",
    "        # BCEWithLogitsLoss already contains a sigmoid function\n",
    "        self.net = nn.Sequential(*net)\n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quantum layers and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_daughter_pt_ratio_delta(inputs, cluster_r=1):\n",
    "    inputs = inputs.reshape((3, -1))\n",
    "    num_particles = inputs.shape[1]\n",
    "    num_qubits = 3 * num_particles\n",
    "    norm_pt, norm_eta, norm_phi = inputs\n",
    "    for ptc in range(num_particles):\n",
    "        qml.RY(2 * torch.asin(norm_pt[ptc]), wires=3*ptc)\n",
    "        qml.RY(2 * torch.asin(norm_pt[ptc]), wires=3*ptc+1)\n",
    "        qml.CRY(2 * torch.asin(norm_eta[ptc]), wires=[3*ptc, 3*ptc+2])\n",
    "        qml.CRY(2 * torch.asin(norm_phi[ptc]), wires=[3*ptc+1, 3*ptc+2])\n",
    "\n",
    "def qml_torch_layer(num_qubits, weight_shapes, enc_layer, qml_layer):\n",
    "    dev = qml.device('default.qubit', wires=num_qubits)\n",
    "    @qml.qnode(dev)\n",
    "    def qnode(inputs, weights):\n",
    "        enc_layer(inputs)\n",
    "        qml_layer(weights=weights, wires=range(num_qubits))\n",
    "        return [qml.expval(qml.PauliZ(wires=i)) for i in range(num_qubits)]\n",
    "    return qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "\n",
    "class HybridModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, hidden_layers, num_qubits, weight_shapes, enc_layer, qml_layer):\n",
    "        super().__init__()\n",
    "        self.num_particles = num_qubits // 3\n",
    "        self.qkernel = qml_torch_layer(num_qubits, weight_shapes, enc_layer, qml_layer)\n",
    "        self.net = ClassicalModel(input_dim+num_qubits, hidden_dim, hidden_layers)\n",
    "    def forward(self, x):\n",
    "        parent_pt_eta_phi = x[:, :3].reshape(-1, 3, 1)\n",
    "        parent_pt, parent_eta, parent_phi = parent_pt_eta_phi[:, 0], parent_pt_eta_phi[:, 1], parent_pt_eta_phi[:, 2]\n",
    "        daughter_pt_eta_phi = x[:, -self.num_particles*3:].reshape(-1, 3, self.num_particles)\n",
    "        daughter_pt, daughter_eta, daughter_phi = daughter_pt_eta_phi[:, 0], daughter_pt_eta_phi[:, 1], daughter_pt_eta_phi[:, 2]\n",
    "        pt_ratio, delta_eta, delta_phi = daughter_pt/parent_pt, daughter_eta-parent_eta, daughter_phi-parent_phi\n",
    "        delta_r, cluster_radius = torch.sqrt(delta_eta**2 + delta_phi**2), 1\n",
    "        norm_pt  = pt_ratio * delta_r / cluster_radius\n",
    "        norm_eta = delta_eta / delta_r\n",
    "        norm_phi = delta_phi / delta_r\n",
    "        assert (torch.abs(norm_pt) <= 1).all() and (torch.abs(norm_eta) <= 1).all() and  (torch.abs(norm_phi) <= 1).all(), \\\n",
    "            f\"Circuit Error : Recieve argument greater than 1 in torch.asin ({torch.abs(norm_pt)}, {torch.abs(norm_eta)}, {torch.abs(norm_phi)})\"\n",
    "        circuit_input = torch.cat((norm_pt, norm_eta, norm_phi), dim=1)\n",
    "        x = torch.cat((x, self.qkernel(circuit_input)), dim=1)\n",
    "        y = self.net(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, config):\n",
    "    model = model.to(GPU)\n",
    "    loss = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "    record = {\"train_loss\":[], \"train_acc\":[], \"test_loss\":[], \"test_acc\":[]}\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        train_loss, train_acc, test_loss, test_acc = 0, 0, 0, 0\n",
    "        model.train()\n",
    "        for x, y_true in data_loader[\"train\"]:\n",
    "            x, y_true = x.to(GPU), y_true.to(GPU)\n",
    "            opt.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            batch_loss = loss(y_pred, y_true)\n",
    "            batch_loss.backward()\n",
    "            train_loss += batch_loss\n",
    "            # BCEWithLogitsLoss -> >=0 | Sigmoid + BCELoss -> >=0.5\n",
    "            train_acc += torch.sum((y_pred >= 0) == y_true) / len(x)\n",
    "            opt.step()\n",
    "        model.eval()\n",
    "        for x, y_true in data_loader[\"test\"]:\n",
    "            x, y_true = x.to(GPU), y_true.to(GPU)\n",
    "            y_pred = model(x)\n",
    "            batch_loss = loss(y_pred, y_true)\n",
    "            test_loss += batch_loss * len(x)\n",
    "            # BCEWithLogitsLoss -> >=0 | Sigmoid + BCELoss -> >=0.5\n",
    "            test_acc += torch.sum((y_pred >= 0) == y_true).item()\n",
    "        train_loss /= len(data_loader[\"train\"])\n",
    "        train_acc /= len(data_loader[\"train\"])\n",
    "        test_loss /= len(data_loader[\"test\"].dataset)\n",
    "        test_acc /= len(data_loader[\"test\"].dataset)\n",
    "        record[\"train_loss\"].append(train_loss)\n",
    "        record[\"train_acc\"].append(train_acc)\n",
    "        record[\"test_loss\"].append(test_loss)\n",
    "        record[\"test_acc\"].append(test_acc)\n",
    "        print(f\"Epoch {epoch+1} : train = (loss:{train_loss:.2f}, acc:{train_acc:.2f}) | test = (loss:{test_loss:.2f}, acc:{test_acc:.2f})\")\n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer (get_parent_info) : ZprimeToZhToZinvhbb.pt not found, create now ...\n",
      "JetEvents : Successfully open /Users/yianchen/CMS_Open_Data_Workspace/CMSSW_7_6_7/src/QCD_Jet_Fatjet/Analyzer/root_files/ZprimeToZhToZinvhbb_1000.root\n",
      "JetEvents : Successfully create ZprimeToZhToZinvhbb with 1000 events.\n",
      "Buffer (get_daughter_info) : ZprimeToZhToZinvhbb.pt not found, create now ...\n",
      "JetEvents : Successfully open /Users/yianchen/CMS_Open_Data_Workspace/CMSSW_7_6_7/src/QCD_Jet_Fatjet/Analyzer/root_files/ZprimeToZhToZinvhbb_1000.root\n",
      "JetEvents : Successfully create ZprimeToZhToZinvhbb with 1000 events.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_daughter_info : Channel ZprimeToZhToZinvhbb with 1000 events: 100%|██████████| 582/582 [00:02<00:00, 278.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer (get_parent_info) : QCD_HT2000toInf.pt not found, create now ...\n",
      "JetEvents : Successfully open /Users/yianchen/CMS_Open_Data_Workspace/CMSSW_7_6_7/src/QCD_Jet_Fatjet/Analyzer/root_files/QCD_HT2000toInf_1000.root\n",
      "JetEvents : Successfully create QCD_HT2000toInf with 1000 events.\n",
      "Buffer (get_daughter_info) : QCD_HT2000toInf.pt not found, create now ...\n",
      "JetEvents : Successfully open /Users/yianchen/CMS_Open_Data_Workspace/CMSSW_7_6_7/src/QCD_Jet_Fatjet/Analyzer/root_files/QCD_HT2000toInf_1000.root\n",
      "JetEvents : Successfully create QCD_HT2000toInf with 1000 events.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_daughter_info : Channel QCD_HT2000toInf with 1000 events: 100%|██████████| 985/985 [00:03<00:00, 268.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Signal = ZprimeToZhToZinvhbb | Background = QCD_HT2000toInf | Cut = (fatjet_pt >= 500) & (fatjet_pt <= 1500)\n",
      "Length Signal = 582 | Length Background = 985 | Number of Data = 582 | Shape = torch.Size([582, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_data_buffer(channel, get_method, *args):\n",
    "    suffix = \" \".join(map(str, args))\n",
    "    buffer_file = f\"data_buffer/{channel}-{get_method.__name__}-{suffix}.pt\"\n",
    "    if not os.path.exists(buffer_file):\n",
    "        print(f\"Buffer ({get_method.__name__}) : {channel}.pt not found, create now ...\")\n",
    "        events = get_method(channel, *args)\n",
    "        torch.save(events, buffer_file)\n",
    "    else:\n",
    "        events = torch.load(buffer_file)\n",
    "        print(f\"Buffer ({get_method.__name__}) : {channel}.pt found, loading complete!\")\n",
    "    return events\n",
    "\n",
    "def get_events(channel, num_events, num_particles, jet_type, cut):\n",
    "    jet_parent = load_data_buffer(channel, jet.get_parent_info, num_events, jet_type, cut)\n",
    "    if num_particles >= 1:\n",
    "        jet_daughter = load_data_buffer(channel, jet.get_daughter_info, num_events, num_particles, jet_type, cut)\n",
    "        return torch.cat((jet_parent, jet_daughter), dim=1)\n",
    "    else:\n",
    "        return jet_parent\n",
    "\n",
    "jet_type   = \"fatjet\"\n",
    "num_events = 1000\n",
    "num_particles = 3\n",
    "cut = f\"({jet_type}_pt >= 500) & ({jet_type}_pt <= 1500)\"\n",
    "\n",
    "signal_channel = \"ZprimeToZhToZinvhbb\"\n",
    "# signal_channel = \"ZprimeToZhToZlephbb\"\n",
    "# background_channel = \"QCD_HT1500to2000\"\n",
    "background_channel = \"QCD_HT2000toInf\"\n",
    "\n",
    "data_ratio = 0.9\n",
    "signal_events = get_events(signal_channel, num_events, num_particles, jet_type, cut)\n",
    "background_events = get_events(background_channel, num_events, num_particles, jet_type, cut)\n",
    "num_sig, num_bkg = len(signal_events), len(background_events)\n",
    "num_data = min(num_sig, num_bkg)\n",
    "num_train = int(data_ratio * num_data)\n",
    "num_test = num_data - num_train\n",
    "print(\"-\" * 100)\n",
    "print(f\"Signal = {signal_channel} | Background = {background_channel} | Cut = {cut}\")\n",
    "print(f\"Length Signal = {num_sig} | Length Background = {num_bkg} | Number of Data = {num_data} | Shape = {signal_events.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JetDataset(Dataset):\n",
    "    def __init__(self, signal_events, background_events):\n",
    "        self.x = torch.cat((signal_events ,background_events))\n",
    "        self.y = torch.cat((torch.ones((len(signal_events)), 1), torch.zeros((len(background_events)), 1)))\n",
    "        self.x.requires_grad = False\n",
    "        self.y.requires_grad = False\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "data_train = JetDataset(signal_events[:num_train], background_events[:num_train])\n",
    "data_test = JetDataset(signal_events[num_train:], background_events[num_train:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : train = (loss:4.84, acc:0.51) | test = (loss:0.59, acc:0.89)\n",
      "Epoch 2 : train = (loss:1.44, acc:0.55) | test = (loss:0.98, acc:0.42)\n",
      "Epoch 3 : train = (loss:0.83, acc:0.55) | test = (loss:0.67, acc:0.56)\n",
      "Epoch 4 : train = (loss:0.70, acc:0.58) | test = (loss:0.80, acc:0.36)\n",
      "Epoch 5 : train = (loss:0.68, acc:0.58) | test = (loss:1.18, acc:0.16)\n",
      "Epoch 6 : train = (loss:0.82, acc:0.55) | test = (loss:1.52, acc:0.17)\n",
      "Epoch 7 : train = (loss:0.82, acc:0.54) | test = (loss:0.42, acc:0.86)\n",
      "Epoch 8 : train = (loss:0.87, acc:0.57) | test = (loss:1.02, acc:0.28)\n",
      "Epoch 9 : train = (loss:0.75, acc:0.55) | test = (loss:0.86, acc:0.41)\n",
      "Epoch 10 : train = (loss:0.79, acc:0.55) | test = (loss:1.39, acc:0.17)\n",
      "Epoch 11 : train = (loss:0.78, acc:0.56) | test = (loss:1.13, acc:0.26)\n",
      "Epoch 12 : train = (loss:0.72, acc:0.58) | test = (loss:0.47, acc:0.84)\n",
      "Epoch 13 : train = (loss:0.72, acc:0.57) | test = (loss:0.56, acc:0.70)\n",
      "Epoch 14 : train = (loss:0.76, acc:0.58) | test = (loss:0.55, acc:0.69)\n",
      "Epoch 15 : train = (loss:1.18, acc:0.51) | test = (loss:1.01, acc:0.38)\n",
      "Epoch 16 : train = (loss:1.05, acc:0.54) | test = (loss:1.89, acc:0.16)\n",
      "Epoch 17 : train = (loss:1.03, acc:0.55) | test = (loss:0.89, acc:0.40)\n",
      "Epoch 18 : train = (loss:0.86, acc:0.56) | test = (loss:0.65, acc:0.54)\n",
      "Epoch 19 : train = (loss:0.70, acc:0.59) | test = (loss:1.17, acc:0.20)\n",
      "Epoch 20 : train = (loss:0.87, acc:0.55) | test = (loss:0.39, acc:0.89)\n",
      "Epoch 21 : train = (loss:0.90, acc:0.57) | test = (loss:0.42, acc:0.88)\n",
      "Epoch 22 : train = (loss:0.85, acc:0.55) | test = (loss:0.47, acc:0.81)\n",
      "Epoch 23 : train = (loss:0.84, acc:0.52) | test = (loss:0.66, acc:0.55)\n",
      "Epoch 24 : train = (loss:0.68, acc:0.63) | test = (loss:0.77, acc:0.44)\n",
      "Epoch 25 : train = (loss:0.70, acc:0.58) | test = (loss:0.62, acc:0.60)\n",
      "Epoch 26 : train = (loss:0.70, acc:0.60) | test = (loss:0.63, acc:0.56)\n",
      "Epoch 27 : train = (loss:0.64, acc:0.63) | test = (loss:0.72, acc:0.47)\n",
      "Epoch 28 : train = (loss:0.67, acc:0.60) | test = (loss:0.57, acc:0.67)\n",
      "Epoch 29 : train = (loss:0.68, acc:0.60) | test = (loss:0.90, acc:0.32)\n",
      "Epoch 30 : train = (loss:0.72, acc:0.58) | test = (loss:0.45, acc:0.87)\n"
     ]
    }
   ],
   "source": [
    "cf = {\n",
    "    \"learning_rate\":1E-3,\n",
    "    \"weight_decay\":0,\n",
    "    \"num_epochs\":30,\n",
    "    \"batch_size\":64,\n",
    "}\n",
    "\n",
    "data_loader = {\n",
    "    \"train\":DataLoader(data_train, cf[\"batch_size\"], shuffle=True, drop_last=True),\n",
    "    \"test\":DataLoader(data_test, cf[\"batch_size\"], shuffle=False, drop_last=False),\n",
    "    }\n",
    "\n",
    "input_dim = signal_events.shape[1]\n",
    "hidden_dim, hidden_layers = 10 * input_dim, 2\n",
    "num_qubits = 3 * num_particles\n",
    "weight_shapes = {\"weights\" : (2, num_qubits)}\n",
    "enc_layer = encode_daughter_pt_ratio_delta\n",
    "qml_layer = qml.BasicEntanglerLayers\n",
    "\n",
    "c_model = ClassicalModel(input_dim, hidden_dim, hidden_layers)\n",
    "# q_model = HybridModel(input_dim, hidden_dim, hidden_layers, num_qubits, weight_shapes, enc_layer, qml_layer)\n",
    "\n",
    "c_result = train(c_model, data_loader, cf)\n",
    "# q_result = train(q_model, data_loader, cf)\n",
    "\n",
    "# np.save(f\"result_arckernel/c_{jet_type}-{signal_channel} vs {background_channel}-{num_particles}-{num_events}-{cut}.npy\", c_result)\n",
    "# np.save(f\"result_arckernel/q_{jet_type}-{signal_channel} vs {background_channel}-{num_particles}-{num_events}-{cut}.npy\", q_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('shims')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f02055337d253f388db8c747d2eda41151d1a914a22500b5c34c6d448cd4f3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
