{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic packages\n",
    "import os, time, random\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# module packages\n",
    "import m_nn\n",
    "import m_lightning\n",
    "\n",
    "# qml\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# pytorch_lightning\n",
    "import lightning as L\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "# pytorch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch_geometric.nn as geom_nn\n",
    "\n",
    "# wandb\n",
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "# wandb login\n",
    "wandb.login()\n",
    "\n",
    "# reproducibility\n",
    "L.seed_everything(3020616)\n",
    "\n",
    "# faster calculation on GPU but less precision\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration dictionary\n",
    "cf = {}\n",
    "cf[\"time\"]     = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "cf[\"wandb\"]    = True\n",
    "cf[\"project\"]  = \"g_polyhedron_geognn\"\n",
    "cf[\"rnd_seed\"] = None # to be determined by for loop\n",
    "\n",
    "# data\n",
    "cf['sig_channel'] = \"tetrahedron\"\n",
    "cf['bkg_channel'] = \"cube\"\n",
    "cf['num_edges']   = None # to be determined by for loop\n",
    "cf['bias_radius'] = 2\n",
    "cf[\"commit\"]      = f\"bias_{cf['bias_radius']}_atan\" # set center of polyhedron -> center of pos = (0,0,0)\n",
    "\n",
    "# model\n",
    "cf['gnn_layers'] = 2\n",
    "\n",
    "# traning configuration\n",
    "cf[\"learning_rate\"]     = 1E-3\n",
    "cf[\"num_data\"]          = 500\n",
    "cf[\"batch_size\"]        = 64\n",
    "cf[\"num_workers\"]       = 0\n",
    "cf[\"max_epochs\"]        = 100\n",
    "cf[\"accelerator\"]       = \"cpu\"\n",
    "cf[\"log_every_n_steps\"] = cf[\"batch_size\"] // 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyhedronDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, num_data, num_edges, coordinate):\n",
    "        super().__init__()\n",
    "        data_list_1 = self._create_data(\"tetrahedron\", num_data, num_edges, coordinate, y=1)\n",
    "        data_list_0 = self._create_data(\"cube\", num_data, num_edges, coordinate, y=0)\n",
    "        random.shuffle(data_list_1)\n",
    "        random.shuffle(data_list_0)\n",
    "        ratio       = 0.8\n",
    "        num_train   = int(ratio * num_data)\n",
    "        self.train_dataset = data_list_1[:num_train] + data_list_0[:num_train]\n",
    "        self.test_dataset  = data_list_1[num_train:] + data_list_0[num_train:]\n",
    "\n",
    "    def _generate_random_unit_vector(self):\n",
    "        # for the algorithm, see\n",
    "        # 1. https://math.stackexchange.com/questions/1585975/how-to-generate-random-points-on-a-sphere\n",
    "        # 2. https://extremelearning.com.au/how-to-generate-uniformly-random-points-on-n-spheres-and-n-balls/\n",
    "        while True:\n",
    "            gaussian_vector  = np.random.randn(3)\n",
    "            vector_magnitude = np.linalg.norm(gaussian_vector)\n",
    "            if vector_magnitude > 1e-5:\n",
    "                break\n",
    "        random_unit_vector = gaussian_vector / vector_magnitude\n",
    "        return random_unit_vector\n",
    "\n",
    "    def _rotation_matrix(self, unit_vector, theta):\n",
    "        # see https://en.wikipedia.org/wiki/Rotation_matrix#Rotation_matrix_from_axis_and_angle\n",
    "        s = np.sin(theta)\n",
    "        c = np.cos(theta)\n",
    "        x, y, z = unit_vector\n",
    "        return np.array([\n",
    "            [c+x*x*(1-c), x*y*(1-c)-z*s, x*z*(1-c)+y*s],\n",
    "            [y*x*(1-c)+z*s, c+y*y*(1-c), y*z*(1-c)-x*s],\n",
    "            [z*x*(1-c)-y*s, z*y*(1-c)+x*s, c+z*z*(1-c)]\n",
    "        ])\n",
    "\n",
    "    def _randomly_rotate(self, nodes):\n",
    "        # the primary node will always be the [0] node\n",
    "        primary_node       = nodes[0]\n",
    "        # randomly choose a unit vector\n",
    "        random_unit_vector = self._generate_random_unit_vector()\n",
    "        # get the unit vector perpendicular to the primary node and the random unit vector\n",
    "        perp_unit_vector   = np.cross(primary_node, random_unit_vector)\n",
    "        perp_unit_vector   = perp_unit_vector / np.linalg.norm(perp_unit_vector)\n",
    "        # get the angle between the primary node and the random unit vector\n",
    "        p, n, v = primary_node, random_unit_vector, perp_unit_vector\n",
    "        if np.sign(np.dot(p, n)) > 0:\n",
    "            angle = np.arcsin(min(np.linalg.norm(perp_unit_vector), 1))\n",
    "        else:\n",
    "            angle = np.pi-np.arcsin(min(np.linalg.norm(perp_unit_vector), 1))\n",
    "        # rotate primary nodes and others with angle\n",
    "        nodes = nodes.T\n",
    "        nodes = self._rotation_matrix(v, angle) @ nodes\n",
    "        # rotate an arbitrary angle with axis n\n",
    "        theta = 2 * np.pi * np.random.rand()\n",
    "        nodes = self._rotation_matrix(n, theta) @ nodes\n",
    "        nodes = nodes.T\n",
    "        return nodes\n",
    "\n",
    "    def _polyhedron_nodes(self, polyhedron):\n",
    "        # tetrahedron\n",
    "        if polyhedron == \"tetrahedron\":\n",
    "            return (1/np.sqrt(3)) * np.array([\n",
    "                [1,1,1], [-1,-1,1], [-1,1,-1], [1,-1,-1]\n",
    "            ])\n",
    "        # cube\n",
    "        elif polyhedron == \"cube\":\n",
    "            return (1/np.sqrt(3)) * np.array([\n",
    "                [1,1,1], [1,1,-1], [1,-1,1], [1,-1,-1],\n",
    "                [-1,1,1], [-1,1,-1], [-1,-1,1], [-1,-1,-1],\n",
    "            ])\n",
    "\n",
    "    def _create_data(self, polyhedron, num_data, num_edges, coordinate, y):\n",
    "        data_list = []\n",
    "        for _ in range(num_data):\n",
    "            # get nodes coordinates\n",
    "            nodes = self._polyhedron_nodes(polyhedron)\n",
    "            # first rotating primary nodes to a random vector then random rotate around it\n",
    "            nodes = self._randomly_rotate(nodes)\n",
    "            # randomly add a small noise\n",
    "            nodes = nodes + 1E-3 * np.random.rand(*np.shape(nodes))\n",
    "            # adding edges, with each node has num_edges edges\n",
    "            edges = []\n",
    "            for i in range(len(nodes)):\n",
    "                # distance between two nodes\n",
    "                distances = [np.linalg.norm(nodes[i] - nodes[j]) for j in range(len(nodes))]\n",
    "                # the first arg is trivial self distance\n",
    "                edges += [(i, idx) for idx in np.argsort(distances)[1:num_edges+1]]\n",
    "            edges = torch.tensor(edges).transpose(0, 1)\n",
    "            # select Cartesian coordinates or Spherical coordinates\n",
    "            nodes = torch.tensor(nodes, dtype=torch.float32)\n",
    "            # randomly give a bias\n",
    "            random_unit_bias = torch.rand(nodes.shape[1])\n",
    "            random_unit_bias = random_unit_bias / torch.norm(random_unit_bias)\n",
    "            random_bias = cf[\"bias_radius\"] * np.random.rand() * random_unit_bias\n",
    "            random_bias = random_bias.repeat(nodes.shape[0], 1)\n",
    "            nodes = nodes + random_bias\n",
    "            if coordinate == \"cartesian\":\n",
    "                pass\n",
    "            elif coordinate == \"spherical\":\n",
    "                nodes_r     = torch.sqrt(torch.sum(nodes**2, dim=1))\n",
    "                nodes_theta = torch.acos(nodes[:,2] / nodes_r).reshape(-1, 1)\n",
    "                nodes_phi   = torch.atan2(nodes[:,1], nodes[:,0]).reshape(-1, 1)\n",
    "                nodes = torch.cat([nodes_theta, nodes_phi], dim=1)\n",
    "            elif coordinate == \"spherical_atan\":\n",
    "                nodes_r     = torch.sqrt(torch.sum(nodes**2, dim=1))\n",
    "                nodes_theta = torch.acos(nodes[:,2] / nodes_r).reshape(-1, 1)\n",
    "                nodes_phi   = torch.atan2(nodes[:,1], nodes[:,0]).reshape(-1, 1)\n",
    "                nodes_atan  = torch.atan(nodes_r).reshape(-1, 1)\n",
    "                nodes = torch.cat([nodes_atan, nodes_theta, nodes_phi], dim=1)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown coordinate type: {coordinate}\")\n",
    "            # check whether nodes are valid -> no nan values\n",
    "            if torch.any(torch.isnan(nodes)):\n",
    "                raise ValueError(f\"{nodes}\")\n",
    "            data_list.append(Data(x=nodes, edge_index=edges, y=y))\n",
    "        return data_list\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=cf[\"batch_size\"], num_workers=cf[\"num_workers\"], shuffle=True)\n",
    "    def val_dataloader(self):\n",
    "        # choose val data to be same as test data, since we just want to monitoring the behavior\n",
    "        return DataLoader(self.test_dataset, batch_size=cf[\"batch_size\"], num_workers=cf[\"num_workers\"])\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=cf[\"batch_size\"], num_workers=cf[\"num_workers\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoMessagePassing(MessagePassing):\n",
    "    def __init__(self, phi, gamma, aggr):\n",
    "        super().__init__(aggr=aggr, flow=\"target_to_source\")\n",
    "        self.phi   = phi\n",
    "        self.gamma = gamma\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.propagate(edge_index, x=x)\n",
    "    def message(self, x_i, x_j):\n",
    "        return self.phi(torch.cat((x_i, x_j), dim=-1))\n",
    "    def update(self, aggr_out, x):\n",
    "        return self.gamma(torch.cat((x, aggr_out), dim=-1))\n",
    "\n",
    "class ClassicalGeoGNN(nn.Module):\n",
    "    def __init__(self, num_features, gnn_layers):\n",
    "        super().__init__()\n",
    "        gnn_phi   = m_nn.ClassicalMLP(in_channel=2*num_features, out_channel=num_features, hidden_channel=2*num_features, num_layers=gnn_layers)\n",
    "        gnn_gamma = m_nn.ClassicalMLP(in_channel=2*num_features, out_channel=1, hidden_channel=0, num_layers=0)\n",
    "        self.gnn  = GeoMessagePassing(gnn_phi, gnn_gamma, aggr=\"sum\")\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.gnn(x, edge_index)\n",
    "        x = geom_nn.global_mean_pool(x, batch)\n",
    "        return x\n",
    "\n",
    "class QuantumGeoGNN(nn.Module):\n",
    "    def __init__(self, num_features, gnn_layers):\n",
    "        super().__init__()\n",
    "        gnn_meas  = [[i, \"X\"] for i in range(num_features)]\n",
    "        gnn_phi   = m_nn.QuantumMLP(num_qubits=2*num_features, num_layers=gnn_layers, num_reupload=0, measurements=gnn_meas)\n",
    "        gnn_gamma = m_nn.ClassicalMLP(in_channel=2*num_features, out_channel=1, hidden_channel=0, num_layers=0)\n",
    "        self.gnn  = GeoMessagePassing(gnn_phi, gnn_gamma, aggr=\"sum\")\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.gnn(x, edge_index)\n",
    "        x = geom_nn.global_mean_pool(x, batch)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_module, commit=\"\", suffix=\"\"):\n",
    "    # wandb logger setup\n",
    "    if cf[\"wandb\"]:\n",
    "        # setup id and path for saving\n",
    "        project  = cf['project']\n",
    "        group    = f\"{cf['time']}_{commit}_{cf['sig_channel']}_{cf['bkg_channel']}\"\n",
    "        job_type = f\"{cf['sig_channel']}_{cf['bkg_channel']}_{cf['num_edges']}\"\n",
    "        name     = f\"{model.__class__.__name__}_gl{cf['gnn_layers']}_{suffix} | {job_type} | rnd_{cf['rnd_seed']} | {cf['time']}\"\n",
    "        id       = f\"{name}\"\n",
    "        # additional information\n",
    "        cf[\"model_structure\"] = f\"gl{cf['gnn_layers']}\"\n",
    "        cf[\"model_name\"]      = model.__class__.__name__\n",
    "        cf[\"group_rnd_seed\"]  = f\"{cf['model_name']}_{cf['model_structure']}_{suffix} | {job_type}\"\n",
    "        cf[\"suffix\"]          = suffix\n",
    "        # tags\n",
    "        tags = [model.__class__.__name__] + [str(cf[key]) for key in cf.keys() if cf[key] is not None]\n",
    "        # wandb logger setup\n",
    "        wandb_logger = WandbLogger(project=project, group=group, job_type=job_type, name=name, id=id, save_dir=f\"./result\", tags=tags)\n",
    "        wandb_logger.experiment.config.update(cf)\n",
    "        wandb_logger.watch(model, log=\"all\")\n",
    "\n",
    "    # start lightning training\n",
    "    logger   = wandb_logger if cf[\"wandb\"] else None\n",
    "    trainer  = L.Trainer(\n",
    "        logger=logger, \n",
    "        accelerator       = cf[\"accelerator\"],\n",
    "        max_epochs        = cf[\"max_epochs\"],\n",
    "        log_every_n_steps = cf[\"log_every_n_steps\"],\n",
    "        )\n",
    "    # LightningModule\n",
    "    litmodel = m_lightning.BinaryLitModel(model, lr=cf[\"learning_rate\"], graph=True)\n",
    "    trainer.fit(litmodel, datamodule=data_module)\n",
    "    trainer.test(litmodel, datamodule=data_module)\n",
    "\n",
    "    # finish wandb monitoring\n",
    "    if cf[\"wandb\"]:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in range(3):\n",
    "    cf[\"num_edges\"] = edge + 1\n",
    "    for rnd_seed in range(3):\n",
    "        # setup\n",
    "        cf[\"rnd_seed\"] = rnd_seed\n",
    "        L.seed_everything(cf[\"rnd_seed\"])\n",
    "\n",
    "        # data module\n",
    "        data_cartesian = PolyhedronDataModule(num_data=cf[\"num_data\"], num_edges=cf[\"num_edges\"], coordinate=\"cartesian\")\n",
    "        data_spherical = PolyhedronDataModule(num_data=cf[\"num_data\"], num_edges=cf[\"num_edges\"], coordinate=\"spherical\")\n",
    "        data_spherical_atan = PolyhedronDataModule(num_data=cf[\"num_data\"], num_edges=cf[\"num_edges\"], coordinate=\"spherical_atan\")\n",
    "\n",
    "        # cartesian\n",
    "        cartesian_2pcnn  = ClassicalGeoGNN(num_features=3, gnn_layers=cf[\"gnn_layers\"])\n",
    "        cartesian_2pcqnn = QuantumGeoGNN(num_features=3, gnn_layers=cf[\"gnn_layers\"])\n",
    "        # train(cartesian_2pcnn, data_cartesian, commit=cf[\"commit\"], suffix=\"cartesian\")\n",
    "        # train(cartesian_2pcqnn, data_cartesian, commit=cf[\"commit\"], suffix=\"cartesian\")\n",
    "\n",
    "        #spherical\n",
    "        spherical_2pcnn  = ClassicalGeoGNN(num_features=2, gnn_layers=cf[\"gnn_layers\"])\n",
    "        spherical_2pcqnn = QuantumGeoGNN(num_features=2, gnn_layers=cf[\"gnn_layers\"])\n",
    "        # train(spherical_2pcnn, data_spherical, commit=cf[\"commit\"], suffix=\"spherical\")\n",
    "        # train(spherical_2pcqnn, data_spherical, commit=cf[\"commit\"], suffix=\"spherical\")\n",
    "\n",
    "        #spherical atan\n",
    "        spherical_2pcnn  = ClassicalGeoGNN(num_features=3, gnn_layers=cf[\"gnn_layers\"])\n",
    "        spherical_2pcqnn = QuantumGeoGNN(num_features=3, gnn_layers=cf[\"gnn_layers\"])\n",
    "        train(spherical_2pcnn, data_spherical_atan, commit=cf[\"commit\"], suffix=\"spherical_atan\")\n",
    "        train(spherical_2pcqnn, data_spherical_atan, commit=cf[\"commit\"], suffix=\"spherical_atan\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
