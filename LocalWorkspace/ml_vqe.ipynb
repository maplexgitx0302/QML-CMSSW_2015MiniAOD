{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jet\n",
    "import uproot\n",
    "import awkward as ak\n",
    "\n",
    "import pennylane as qml\n",
    "import pennylane.numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_nsubjettiness(channel, num_events):\n",
    "    root_path = f\"../ZprimeToZh_VS_QCD/Analyzer/root_files/{channel}_{num_events}.root\"\n",
    "    root_file = uproot.open(root_path)\n",
    "    root_events = root_file['jets/Events']\n",
    "    jet_events = jet.JetEvents(root_events, jet_type=\"fatjet\", keep_by=\"pt\")\n",
    "    trimmed_events = torch.stack((\n",
    "        torch.tensor(jet_events.nsubjettiness[\"tau1\"]),\n",
    "        torch.tensor(jet_events.nsubjettiness[\"tau2\"]),\n",
    "        torch.tensor(jet_events.nsubjettiness[\"tau3\"]),\n",
    "    ))\n",
    "    trimmed_events = torch.transpose(trimmed_events, 0, 1)\n",
    "    return trimmed_events\n",
    "\n",
    "def get_data_pt_eta_phi(channel, num_events, num_particles, jet_type):\n",
    "    root_path = f\"../ZprimeToZh_VS_QCD/Analyzer/root_files/{channel}_{num_events}.root\"\n",
    "    root_file = uproot.open(root_path)\n",
    "    root_events = root_file['jets/Events']\n",
    "    jet_events = jet.JetEvents(root_events, jet_type, keep_by=\"pt\")\n",
    "\n",
    "    trimmed_events = torch.zeros((num_events, 3 * num_particles))\n",
    "    idx_argsort = ak.argsort(jet_events.daughter[\"pt\"], ascending=False)\n",
    "    for i in range(num_events):\n",
    "        for j in range(min(len(idx_argsort[i]), num_particles)):\n",
    "            trimmed_events[i][3*j+0] = jet_events.daughter[\"pt\"][i][idx_argsort[i][j]]\n",
    "            trimmed_events[i][3*j+1] = jet_events.daughter[\"eta\"][i][idx_argsort[i][j]]\n",
    "            trimmed_events[i][3*j+2] = jet_events.daughter[\"phi\"][i][idx_argsort[i][j]]\n",
    "    return trimmed_events\n",
    "\n",
    "\n",
    "class JetData(Dataset):\n",
    "    def __init__(self, signal_events, background_events):\n",
    "        self.x = torch.cat((signal_events ,background_events))\n",
    "        self.y = torch.cat((torch.ones((len(signal_events)), 1), torch.zeros((len(background_events)), 1)))\n",
    "        print(self.x.shape, self.y.shape)\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicalModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=0, hidden_layers=0):\n",
    "        super().__init__()\n",
    "        if hidden_layers == 0:\n",
    "            net = [nn.Linear(input_dim, 1), nn.ReLU()]\n",
    "        else:\n",
    "            net = []\n",
    "            net.append(nn.Linear(input_dim, hidden_dim))\n",
    "            net.append(nn.ReLU())\n",
    "            for _ in range(hidden_layers):\n",
    "                net.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "                net.append(nn.ReLU())\n",
    "            net.append(nn.Linear(hidden_dim, 1))\n",
    "        # BCEWithLogitsLoss already contains a sigmoid function\n",
    "        self.net = nn.Sequential(*net)\n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        return y\n",
    "\n",
    "class HybridModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=0, hidden_layers=0):\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, cf):\n",
    "    loss = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=cf[\"learning_rate\"], weight_decay=cf[\"weight_decay\"])\n",
    "    for epoch in range(cf[\"num_epochs\"]):\n",
    "        train_loss, train_acc, train_count = 0, 0, 0\n",
    "        test_loss, test_acc = 0, 0\n",
    "        model.train()\n",
    "        for x, y_true in data_loader[\"train\"]:\n",
    "            opt.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            batch_loss = loss(y_pred, y_true)\n",
    "            batch_loss.backward()\n",
    "            train_count += 1\n",
    "            train_loss += batch_loss.detach()\n",
    "            # BCEWithLogitsLoss -> >=0 | Sigmoid + BCELoss -> >=0.5\n",
    "            train_acc += torch.sum((y_pred >= 0) == y_true) / len(x)\n",
    "            opt.step()\n",
    "        model.eval()\n",
    "        for x, y_true in data_loader[\"test\"]:\n",
    "            y_pred = model(x)\n",
    "            batch_loss = loss(y_pred, y_true)\n",
    "            test_loss += batch_loss.detach() * len(x)\n",
    "            # BCEWithLogitsLoss -> >=0 | Sigmoid + BCELoss -> >=0.5\n",
    "            test_acc += torch.sum((y_pred >= 0) == y_true).item()\n",
    "        train_loss /= train_count\n",
    "        train_acc /= train_count\n",
    "        test_loss /= len(data_loader[\"test\"].dataset)\n",
    "        test_acc /= len(data_loader[\"test\"].dataset)\n",
    "        print(f\"Epoch {epoch} : train = ({train_loss:.2f}, {train_acc:.2f}) | test = ({test_loss:.2f}, {test_acc:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1800, 15]) torch.Size([1800, 1])\n",
      "torch.Size([200, 15]) torch.Size([200, 1])\n"
     ]
    }
   ],
   "source": [
    "num_events = 1000\n",
    "num_particles = 5\n",
    "data_ratio = 0.9\n",
    "num_train = int(data_ratio * num_events)\n",
    "num_test = num_events - num_train\n",
    "\n",
    "# signal_channel = \"ZprimeToZhToZinvhbb\"\n",
    "signal_channel = \"ZprimeToZhToZlephbb\"\n",
    "# background_channel = \"QCD_HT1500to2000\"\n",
    "background_channel = \"QCD_HT2000toInf\"\n",
    "\n",
    "# signal_events = get_data_nsubjettiness(signal_channel, num_events)\n",
    "# background_events = get_data_nsubjettiness(background_channel, num_events)\n",
    "signal_events = get_data_pt_eta_phi(signal_channel, num_events, num_particles, jet_type=\"fatjet\")\n",
    "background_events = get_data_pt_eta_phi(background_channel, num_events, num_particles, jet_type=\"fatjet\")\n",
    "\n",
    "data_train = JetData(signal_events[:num_train], background_events[:num_train])\n",
    "data_test = JetData(signal_events[num_train:], background_events[num_train:])\n",
    "data_loader = {\n",
    "    \"train\":DataLoader(data_train, 32, shuffle=True, drop_last=True),\n",
    "    \"test\":DataLoader(data_test, 32, shuffle=False, drop_last=False),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : train = (1.62, 0.63) | test = (0.53, 0.70)\n",
      "Epoch 1 : train = (0.49, 0.78) | test = (0.45, 0.82)\n",
      "Epoch 2 : train = (0.40, 0.85) | test = (0.39, 0.83)\n",
      "Epoch 3 : train = (0.30, 0.90) | test = (0.39, 0.85)\n",
      "Epoch 4 : train = (0.29, 0.88) | test = (0.28, 0.88)\n",
      "Epoch 5 : train = (0.24, 0.91) | test = (0.32, 0.86)\n",
      "Epoch 6 : train = (0.24, 0.91) | test = (0.26, 0.90)\n",
      "Epoch 7 : train = (0.21, 0.92) | test = (0.32, 0.87)\n",
      "Epoch 8 : train = (0.22, 0.92) | test = (0.26, 0.90)\n",
      "Epoch 9 : train = (0.20, 0.93) | test = (0.28, 0.90)\n",
      "Epoch 10 : train = (0.21, 0.92) | test = (0.27, 0.89)\n",
      "Epoch 11 : train = (0.20, 0.93) | test = (0.27, 0.88)\n",
      "Epoch 12 : train = (0.22, 0.91) | test = (0.31, 0.88)\n",
      "Epoch 13 : train = (0.23, 0.92) | test = (0.27, 0.90)\n",
      "Epoch 14 : train = (0.22, 0.91) | test = (0.26, 0.91)\n",
      "Epoch 15 : train = (0.21, 0.92) | test = (0.29, 0.89)\n",
      "Epoch 16 : train = (0.21, 0.92) | test = (0.28, 0.89)\n",
      "Epoch 17 : train = (0.20, 0.93) | test = (0.28, 0.90)\n",
      "Epoch 18 : train = (0.20, 0.93) | test = (0.26, 0.91)\n",
      "Epoch 19 : train = (0.21, 0.92) | test = (0.29, 0.89)\n",
      "Epoch 20 : train = (0.18, 0.93) | test = (0.26, 0.91)\n",
      "Epoch 21 : train = (0.21, 0.92) | test = (0.32, 0.86)\n",
      "Epoch 22 : train = (0.20, 0.93) | test = (0.26, 0.91)\n",
      "Epoch 23 : train = (0.19, 0.92) | test = (0.25, 0.91)\n",
      "Epoch 24 : train = (0.19, 0.93) | test = (0.27, 0.90)\n",
      "Epoch 25 : train = (0.21, 0.92) | test = (0.30, 0.89)\n",
      "Epoch 26 : train = (0.20, 0.93) | test = (0.25, 0.90)\n",
      "Epoch 27 : train = (0.19, 0.93) | test = (0.25, 0.90)\n",
      "Epoch 28 : train = (0.18, 0.93) | test = (0.27, 0.90)\n",
      "Epoch 29 : train = (0.19, 0.92) | test = (0.27, 0.90)\n",
      "Epoch 30 : train = (0.18, 0.93) | test = (0.31, 0.88)\n",
      "Epoch 31 : train = (0.20, 0.92) | test = (0.25, 0.91)\n",
      "Epoch 32 : train = (0.18, 0.93) | test = (0.31, 0.87)\n",
      "Epoch 33 : train = (0.19, 0.93) | test = (0.25, 0.91)\n",
      "Epoch 34 : train = (0.20, 0.92) | test = (0.26, 0.90)\n",
      "Epoch 35 : train = (0.19, 0.93) | test = (0.25, 0.92)\n",
      "Epoch 36 : train = (0.18, 0.93) | test = (0.27, 0.91)\n",
      "Epoch 37 : train = (0.19, 0.93) | test = (0.27, 0.90)\n",
      "Epoch 38 : train = (0.18, 0.93) | test = (0.25, 0.91)\n",
      "Epoch 39 : train = (0.18, 0.93) | test = (0.27, 0.90)\n",
      "Epoch 40 : train = (0.20, 0.93) | test = (0.26, 0.91)\n",
      "Epoch 41 : train = (0.20, 0.93) | test = (0.25, 0.90)\n",
      "Epoch 42 : train = (0.20, 0.92) | test = (0.25, 0.90)\n",
      "Epoch 43 : train = (0.19, 0.93) | test = (0.26, 0.91)\n",
      "Epoch 44 : train = (0.19, 0.93) | test = (0.31, 0.86)\n",
      "Epoch 45 : train = (0.20, 0.92) | test = (0.30, 0.88)\n",
      "Epoch 46 : train = (0.20, 0.92) | test = (0.25, 0.91)\n",
      "Epoch 47 : train = (0.18, 0.93) | test = (0.34, 0.88)\n",
      "Epoch 48 : train = (0.21, 0.92) | test = (0.29, 0.88)\n",
      "Epoch 49 : train = (0.19, 0.93) | test = (0.28, 0.90)\n"
     ]
    }
   ],
   "source": [
    "cf = {\n",
    "    \"learning_rate\":1E-2,\n",
    "    \"weight_decay\":0,\n",
    "    \"num_epochs\":50,\n",
    "}\n",
    "\n",
    "# c_model = ClassicalModel(input_dim=3, hidden_dim=128, hidden_layers=4) # n-subjettiness\n",
    "c_model = ClassicalModel(input_dim=3*num_particles, hidden_dim=16*num_particles, hidden_layers=2) # pt eta phi\n",
    "train(c_model, data_loader, cf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('shims')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f02055337d253f388db8c747d2eda41151d1a914a22500b5c34c6d448cd4f3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
